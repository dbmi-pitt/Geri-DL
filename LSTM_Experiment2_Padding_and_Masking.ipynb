{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version:  3.7.3 (default, Mar 27 2019, 22:11:17) \n",
      "[GCC 7.3.0]\n",
      "pandas version:  0.24.2\n",
      "numpy version:  1.16.4\n",
      "scipy version:  1.3.0\n",
      "sklearn version:  0.21.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras version:  2.2.4\n",
      "keras backend:  tensorflow\n",
      "tensorflow version:  1.14.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"python version: \", sys.version)\n",
    "\n",
    "import pandas as pd\n",
    "print(\"pandas version: \", pd.__version__)\n",
    "\n",
    "import numpy as np\n",
    "print('numpy version: ', np.__version__)\n",
    "\n",
    "import scipy as sp\n",
    "print('scipy version: ', sp.__version__)\n",
    "\n",
    "import sklearn as skl\n",
    "print('sklearn version: ', skl.__version__)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "import keras as ks\n",
    "print('keras version: ', ks.__version__)\n",
    "print('keras backend: ', ks.backend.backend())\n",
    "\n",
    "import tensorflow as tf\n",
    "print('tensorflow version: ', tf.__version__)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "from sklearn.metrics import roc_curve, auc, f1_score, accuracy_score, precision_recall_curve\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7584, 208)\n"
     ]
    }
   ],
   "source": [
    "excel_file = r'geriomop-data-from-egems-paper-UPDATED-COL-FIX-ATC_2-and-behavior-change-022819.tsv'\n",
    "df = pd.DataFrame(pd.read_csv(excel_file, sep='\\t'))\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop features\n",
    "f_drop = [\"Blank-1\", \"ws-sudden-stop\", \"ws-sudden-stop-drugs\", \"ws-prolonged-psychotropics\", \"mds-toilet-prgm-atmptd\"] + \\\n",
    "         ['Deleted-%d' % i for i in range(1, 13)] + ['Psychotropic-%d' % i for i in range(1, 6)] + \\\n",
    "         ['Psychotropic-%d-average-daily-dose' % i for i in range(1, 6)] + [\"Entry-discharge-type\"]\n",
    "\n",
    "# Missing value means not relevant\n",
    "f_one_hot = [\"Mds-fall-2-6-months-to-admission\", \"Mds-fall-last-month-to-admission\", \"mds-pain-last-five-days\", \\\n",
    "             \"mds-delirium-scale\", \"mds-long-term-memory-ok\", \"mds-short-term-memory-ok\", \"mds-staff-assess-pain\", \\\n",
    "             \"recent-start-other-fall-risk-rx\"] + [\"mds-pressure-ulcer-stage-%d\" % i for i in range(1, 5)]\n",
    "cate_one_hot = [['Yes', 'No', 'Unable to answer']] * 3 + [['Yes', 'No']] * 9\n",
    "\n",
    "f_period = [(\"Psychotropic-%d-Start-date\" % i, 'Psychotropic-%d-End-date' % i, 'Psychotropic-%d-Period' % i) for i in range(1, 6)]\n",
    "\n",
    "f_label = ['mds-cognitive-scale', 'mds-pain-freq-last-five-days', 'mds-pain-intensity']\n",
    "dic_label = [{'Independent': 0, 'Modified Independence': 1, 'Moderately Impaired': 2, 'Severely Impaired': 3}, \\\n",
    "             {'Continuous': 4, 'Frequent': 3, 'Occasional': 2, 'Rare': 1, 'Unable to respond': 0}, \\\n",
    "             {'None': 0, 'Mild': 1, 'Moderate': 2, 'Severe': 3, 'Very severe, horrible': 4}]\n",
    "\n",
    "f_transform = [('mds-cognitive-scale', 3, 0), ('mds-pain-freq-last-five-days', 4, 0), ('mds-pain-intensity', 4, 0)] + \\\n",
    "              [('Psychotropic-%d-Period' % i, 0, 0) for i in range(1, 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode features (originally) with no missing values\n",
    "f_drop += [\"predictor-date\", \"projected-date\", \"PPS-assessment\", \"Federal-assessment\"]\n",
    "\n",
    "f_period += [('episode-start-date', 'episode-end-date', 'episode-period'),\\\n",
    "             ('stay-start-date', 'stay-end-date', 'stay-period')]\n",
    "\n",
    "f_label += [\"cms-long-stay\", \"mds-stay-trans-short-to-long\", \"mds-antianxiety-medication\", \\\n",
    "            \"mds-antidepressant-medication\", \"mds-antipsychotic-medication\", \"mds-antibiotic-medication\",\n",
    "            \"mds-anticoagulant-medication\", \"mds-diuretic-medication\", \\\n",
    "            \"mds-hypnotic-medication\", \"mds-behavioral-symptoms\", \"mds-behavioral-symptoms-to-others\", \\\n",
    "            \"mds-dehydrated\", \"mds-depression\", \"mds-fever\", \"mds-impaired-mobility\", \"mds-impaired-transfer\", \\\n",
    "            \"mds-internal-bleeding\", \"mds-malnutrition\", \"mds-no-problem-conditions\", \"mds-vomiting\", \\\n",
    "            \"mds-impaired-walk-in-room\", \"mds-impaired-walk-in-corridor\", \"mds-impaired-locomot-unit\", \\\n",
    "            \"mds-impaired-locomot-other\", \"ws-antibiotic-anticoag-coexposure\", \\\n",
    "            \"ws-psychotropic-with-not-ordered-weight-loss\", \\\n",
    "            \"ws-diuretic-adl\", \"ws-tramadol-antidepressant-coexposure\"] + [\"mds-pain-non-verbal\"]\n",
    "dic_label += [{'Yes': 1, 'No': 0}] * 28 + [{'None/Mild':0,'Moderate/Severe':1}]\n",
    "\n",
    "f_one_hot += [\"race\", \"facility\", \"gender\", \"mds-bims-summary-ranking\", \"ws-meclizine-psych-coexposure\"]\n",
    "cate_one_hot += [['White', 'Black', 'Other'], \\\n",
    "                 ['Sugar Creek', 'Heritage Place', 'Canterbury Place', 'Senaca Place', 'Cranberry Place'], \\\n",
    "                 ['Female', 'Male'], ['Intact or Moderately Intact', 'Moderate Impairment'], \\\n",
    "                 ['No', 'meclAndPsychStartSameR', 'meclPrecedesPsychR', 'psychPrecedesMeclR', 'meclAndPsychOlderStart']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features need imputation\n",
    "f_one_hot += [\"pneumonia\", \"uti\", \"mdro\", \"anemia\", \"septicemia\", \"constipation\", \"wound\", \"hyponatremia\", \\\n",
    "              \"hyperkalemia\", \"embolisms\", \"alzheimers\", \"anxiety\", \"depression\", \"non-alz-dimentia\", \"bipolar\", \\\n",
    "              \"parkinsons\", \"psychosis\", \"schizophrenia\", \"seizure\", \"aphasia\", \"emphysema\", \"arthritis\", \"ashd\", \\\n",
    "              \"bph\", \"cancer\", \"cerebralpalsy\", \"stroke\", \"cirrhosis\", \"comatose\", \"diabetes\", \"dysrhythmias\", \"gerd\", \\\n",
    "              \"heart-failure\", \"hemiplegia/hemiparesis\", \"hepatitis\", \"huntingtons\", \"hyperlipidemia\", \"hyperthyroidism\", \\\n",
    "              \"hypothyroidism\", \"hypertension\", \"hypotension\", \"multiple-sclerosis\", \"neurogenic-bladder\", \\\n",
    "              \"obstructive-uropathy\", \"osteoporosis\", \"paraplegia\", \"ptsd\", \"pvd\", \"quadriplegia\", \"thyroid-disorder\",\\\n",
    "              \"tourettes\", \"transient-ischemic-attack\", \"traumatic-brain-injury\", \"tuberculosis\", \"renal-failure\",\\\n",
    "              \"mds-delirium-scale\", \"mds-pain-medication\", \"mds-received-pain-tx-non-pharm\", \\\n",
    "              \"mds-received-prn-pain-medication\", \"mds-conduct-staff-assessment-mental-status\", \\\n",
    "              \"mds-pressure-ulcer-prsnt\", \"conduct_bims\", \"acute_mental_change\", \"conduct_pain_assmnt\", \\\n",
    "              \"cane_or_crutch_past_7_days\", \"walker_past_7_days\", \"wheelchair_past_7_days\", \\\n",
    "              \"limb_prosthesis_past_7_days\", \"no_listed_mobility_device\"] + \\\n",
    "              [\"balance_while_standing\", \"balance_while_walking\", \"balance_turning_around\", \\\n",
    "               \"balance_toileting\", \"balance_bed_to_chair\"] + \\\n",
    "              [\"marital-status\", \"mds-entered-from\", \"mds-excess-weight-loss\"]\n",
    "cate_one_hot += [['Yes', 'No']] * 69 + \\\n",
    "                [[\"Steady at all times\", \"able to stabilize without assistance\", \\\n",
    "                  \"able to stabilize with assistance\", \"Activity did not occur\"]] * 5 + \\\n",
    "                [[\"Never Married\", \"Married\", \"Widowed\", \"Separated\", \"Divorced\"], \\\n",
    "                 [\"Acute Hospital\", \"Psychiatric Hospital\", \"Another nursing home or swing bed\", \"Hospice\", \\\n",
    "                  \"Inpatient rehabilitation facility\",\n",
    "                  \"Community (private home/apt., board/care, assisted living, group home)\", \"Other\"],\n",
    "                 [\"Yes - prescribed\", \"Yes - not prescribed\", \"No or unknown\"]]\n",
    "\n",
    "f_label += [\"mds-urinary-incontinence\", \"functlimit_rom_upper\", \"functlimit_rom_lower\", \"does_resident_wander\"] + \\\n",
    "           [\"cam_inattention\", \"cam_disorganized_thought\", \"cam_altered_conc\", \"cam_motor_retardation\"]\n",
    "dic_label += [{\"Always continent\": 0, \"Occasionally incontinent\": 1, \"Frequently incontinent\": 2,\\\n",
    "               \"Always incontinent\": 3, \"Catheter - not rated\": np.nan}] + \\\n",
    "             [{\"No impairment\": 0, \"Impairment on one side\": 1, \"Impairment on both sides\": 2}] * 2 + \\\n",
    "             [{\"Behavior not exhibited\": 0, \"1 to 3 days\": 1, \"4 to 6 days\": 2, \"occurred daily\": 3}] + \\\n",
    "             [{\"Behavior not present\": 0, \"Behavior present, fluctuates\": 1, \"Behavior continuously present\": 2}] * 4\n",
    "\n",
    "f_transform += [(\"mds-urinary-incontinence\", 3, 0), (\"cam_inattention\", 2, 0), (\"cam_disorganized_thought\", 2, 0), \\\n",
    "                (\"cam_altered_conc\", 2, 0), (\"cam_motor_retardation\", 2, 0), (\"functlimit_rom_upper\", 2, 0), \\\n",
    "                (\"functlimit_rom_lower\", 2, 0), (\"does_resident_wander\", 3, 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set sdd=0 to NA\n",
    "for i in range(1, 6):\n",
    "    df.loc[df['psych_sdd_%d' % i] == 0, 'psych_sdd_%d' % i] = np.nan\n",
    "# These data were dropped in Experiment 1\n",
    "f_transform += [('psych_sdd_%d' % i, 0, 0) for i in range(1, 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping min effective dose and one hot encoding ATC psychotropic drugs\n",
    "# These data were not used in Experiment 1 b/c of missing values\n",
    "f_drop += [\"min_effective_dose_%d\" % i for i in range(1, 6)]\n",
    "\n",
    "atc_list = []\n",
    "for i in range(1, 6):\n",
    "    atc_list.append(df.groupby('atc_%d' % i)['min_effective_dose_%d' % i].first())\n",
    "atc_codes = pd.concat(atc_list)\n",
    "atc_codes = atc_codes[~atc_codes.index.duplicated()].index.tolist()\n",
    "f_one_hot += [\"atc_%d\" % i for i in range(1, 6)]\n",
    "cate_one_hot += [atc_codes] * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate target\n",
    "target = df['outcome-Mds-fall-since-prior-assessment'].map({'None': 0, 'Yes': 1})\n",
    "dff = df.drop(['outcome-mds-fall-no-injury', 'outcome-mds-fall-minor-injury', 'outcome-mds-fall-major-injury', \\\n",
    "               'outcome-Mds-fall-since-prior-assessment', 'outcome-riskmaster-fall-incident'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "def train_test_split(df, target, groupby, radio, random_state):\n",
    "    train_idx, test_idx = next(GroupShuffleSplit(train_size=radio, test_size=1-radio, random_state=random_state).split(df, target, df[groupby]))\n",
    "    return df.iloc[train_idx], df.iloc[test_idx], target.iloc[train_idx], target.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of patients: 3133\n",
      "Number of patients in training set: 2193\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dff, target, 'patient-id', 0.7, 0)\n",
    "print('Total number of patients: %d' % len(df.groupby('patient-id')))\n",
    "print('Number of patients in training set: %d' % len(X_train.groupby('patient-id')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop feature\n",
    "def drop_features(df, f):\n",
    "    df.drop(f, axis=1, inplace=True)\n",
    "    \n",
    "# one hot encoding\n",
    "def one_hot_encoding(df, features, categories):\n",
    "    for f, c in zip(features, categories):\n",
    "        df[f] = df[f].astype('category', categories=c)\n",
    "    return pd.get_dummies(df, columns=features, prefix=features)\n",
    "\n",
    "# compute date difference\n",
    "def date_diff(start, end):\n",
    "    return (pd.to_datetime(end) - pd.to_datetime(start)) / np.timedelta64(1, 'D')\n",
    "\n",
    "# generate date diff features\n",
    "def generate_period(df, f):\n",
    "    for start, end, period in f:\n",
    "        df[period] = date_diff(df[start], df[end])\n",
    "        df.drop([start, end], axis=1, inplace=True)\n",
    "        \n",
    "# label encoding\n",
    "def label_encoding(df, features, dictionaries):\n",
    "    for f, dic in zip(features, dictionaries):\n",
    "        df[f] = df[f].map(dic)\n",
    "        \n",
    "# sin&cos transform\n",
    "def col_transform(df, col, mmax, mmin, df_ref=None):\n",
    "    if(mmax <= mmin):\n",
    "        # for test set, if max&min not set, use training set value\n",
    "        if(df_ref is not None): \n",
    "            mmax = df_ref[col].max()\n",
    "            mmin = df_ref[col].max()\n",
    "        else:\n",
    "            mmax = df[col].max()\n",
    "            mmin = df[col].min()\n",
    "    angle = 0.25 * np.pi * (df[col] - mmin) / (mmax - mmin) + 0.125 * np.pi\n",
    "    return (np.cos(angle), np.sin(angle))\n",
    "\n",
    "def df_transform(df, f, df_ref=None):\n",
    "    for col, mmax, mmin in f:\n",
    "        df[col + '_x'], df[col + '_y'] = col_transform(df, col, mmax, mmin, df_ref)\n",
    "        df[col + '_x'].fillna(0, inplace=True)\n",
    "        df[col + '_y'].fillna(0, inplace=True)\n",
    "        df.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 23s, sys: 1.46 s, total: 1min 25s\n",
      "Wall time: 27.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Training set data reshaping\n",
    "generate_period(X_train, f_period)\n",
    "label_encoding(X_train, f_label, dic_label)\n",
    "X_train_original = X_train.copy() # store value range\n",
    "df_transform(X_train, f_transform)\n",
    "X_train = one_hot_encoding(X_train, f_one_hot, cate_one_hot)\n",
    "drop_features(X_train, f_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_use = X_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X_train.dtypes[X_train.dtypes == 'object'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [count, percentage]\n",
       "Index: []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing data describe\n",
    "def missing_summary(df):\n",
    "    missing_cnt = df.isna().sum()\n",
    "    missing_data = pd.concat([missing_cnt, missing_cnt/df.shape[0]], axis=1, keys=['count', 'percentage'])\n",
    "    return missing_data[missing_data['percentage'] != 0].sort_values(by='percentage', ascending=False)\n",
    "\n",
    "missing_summary(X_train_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.7 s, sys: 60.5 ms, total: 25.8 s\n",
      "Wall time: 25.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Test set data reshaping\n",
    "generate_period(X_test, f_period)\n",
    "label_encoding(X_test, f_label, dic_label)\n",
    "df_transform(X_test, f_transform, X_train_original)\n",
    "X_test = one_hot_encoding(X_test, f_one_hot, cate_one_hot)\n",
    "drop_features(X_test, f_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_use = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X_test.dtypes[X_test.dtypes == 'object'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [count, percentage]\n",
       "Index: []"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_summary(X_test_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5301, 524)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_use.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2283, 524)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_use.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient-id</th>\n",
       "      <th>current-stay-days</th>\n",
       "      <th>cumulative-days-in-facility</th>\n",
       "      <th>cms-long-stay</th>\n",
       "      <th>mds-stay-trans-short-to-long</th>\n",
       "      <th>age</th>\n",
       "      <th>mds-antianxiety-medication</th>\n",
       "      <th>mds-antidepressant-medication</th>\n",
       "      <th>mds-antipsychotic-medication</th>\n",
       "      <th>mds-antibiotic-medication</th>\n",
       "      <th>...</th>\n",
       "      <th>atc_5_N06AB10</th>\n",
       "      <th>atc_5_N06AX05</th>\n",
       "      <th>atc_5_N06AX11</th>\n",
       "      <th>atc_5_N06AX12</th>\n",
       "      <th>atc_5_N06AX16</th>\n",
       "      <th>atc_5_N06AX21</th>\n",
       "      <th>atc_5_N06AX24</th>\n",
       "      <th>atc_5_N05AA01</th>\n",
       "      <th>atc_5_N05BA05</th>\n",
       "      <th>atc_5_N06AX23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10353</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10364</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10386</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5000</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5003</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 524 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient-id  current-stay-days  cumulative-days-in-facility  cms-long-stay  \\\n",
       "0       10353                  7                            7              0   \n",
       "1       10364                  7                            7              0   \n",
       "4       10386                  7                            7              0   \n",
       "5        5000                  7                            7              0   \n",
       "6        5003                  7                            7              0   \n",
       "\n",
       "   mds-stay-trans-short-to-long  age  mds-antianxiety-medication  \\\n",
       "0                             0   67                           1   \n",
       "1                             1   84                           0   \n",
       "4                             1   77                           1   \n",
       "5                             0   90                           0   \n",
       "6                             1   90                           0   \n",
       "\n",
       "   mds-antidepressant-medication  mds-antipsychotic-medication  \\\n",
       "0                              1                             0   \n",
       "1                              0                             1   \n",
       "4                              1                             1   \n",
       "5                              1                             1   \n",
       "6                              1                             1   \n",
       "\n",
       "   mds-antibiotic-medication  ...  atc_5_N06AB10  atc_5_N06AX05  \\\n",
       "0                          0  ...              0              0   \n",
       "1                          1  ...              0              0   \n",
       "4                          0  ...              0              0   \n",
       "5                          0  ...              0              0   \n",
       "6                          1  ...              0              0   \n",
       "\n",
       "   atc_5_N06AX11  atc_5_N06AX12  atc_5_N06AX16  atc_5_N06AX21  atc_5_N06AX24  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "5              0              0              0              0              0   \n",
       "6              0              0              0              0              0   \n",
       "\n",
       "   atc_5_N05AA01  atc_5_N05BA05  atc_5_N06AX23  \n",
       "0              0              0              0  \n",
       "1              0              0              0  \n",
       "4              0              0              0  \n",
       "5              0              0              0  \n",
       "6              0              0              0  \n",
       "\n",
       "[5 rows x 524 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_use.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_use.to_csv (r'/tmp/export_train_dataframe.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient-id</th>\n",
       "      <th>current-stay-days</th>\n",
       "      <th>cumulative-days-in-facility</th>\n",
       "      <th>cms-long-stay</th>\n",
       "      <th>mds-stay-trans-short-to-long</th>\n",
       "      <th>age</th>\n",
       "      <th>mds-antianxiety-medication</th>\n",
       "      <th>mds-antidepressant-medication</th>\n",
       "      <th>mds-antipsychotic-medication</th>\n",
       "      <th>mds-antibiotic-medication</th>\n",
       "      <th>...</th>\n",
       "      <th>atc_5_N06AB10</th>\n",
       "      <th>atc_5_N06AX05</th>\n",
       "      <th>atc_5_N06AX11</th>\n",
       "      <th>atc_5_N06AX12</th>\n",
       "      <th>atc_5_N06AX16</th>\n",
       "      <th>atc_5_N06AX21</th>\n",
       "      <th>atc_5_N06AX24</th>\n",
       "      <th>atc_5_N05AA01</th>\n",
       "      <th>atc_5_N05BA05</th>\n",
       "      <th>atc_5_N06AX23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10379</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10385</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5032</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5032</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5032</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 524 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    patient-id  current-stay-days  cumulative-days-in-facility  cms-long-stay  \\\n",
       "2        10379                  7                            7              0   \n",
       "3        10385                  7                            7              0   \n",
       "14        5032                  7                            7              0   \n",
       "15        5032                  8                            8              0   \n",
       "16        5032                  7                            7              0   \n",
       "\n",
       "    mds-stay-trans-short-to-long  age  mds-antianxiety-medication  \\\n",
       "2                              0   84                           0   \n",
       "3                              1   85                           0   \n",
       "14                             0   85                           1   \n",
       "15                             0   86                           1   \n",
       "16                             0   86                           1   \n",
       "\n",
       "    mds-antidepressant-medication  mds-antipsychotic-medication  \\\n",
       "2                               1                             0   \n",
       "3                               1                             0   \n",
       "14                              1                             0   \n",
       "15                              1                             0   \n",
       "16                              1                             0   \n",
       "\n",
       "    mds-antibiotic-medication  ...  atc_5_N06AB10  atc_5_N06AX05  \\\n",
       "2                           0  ...              0              0   \n",
       "3                           1  ...              0              0   \n",
       "14                          1  ...              0              0   \n",
       "15                          1  ...              0              0   \n",
       "16                          1  ...              0              0   \n",
       "\n",
       "    atc_5_N06AX11  atc_5_N06AX12  atc_5_N06AX16  atc_5_N06AX21  atc_5_N06AX24  \\\n",
       "2               0              0              0              0              0   \n",
       "3               0              0              0              0              0   \n",
       "14              0              0              0              0              0   \n",
       "15              0              0              0              0              0   \n",
       "16              0              0              0              0              0   \n",
       "\n",
       "    atc_5_N05AA01  atc_5_N05BA05  atc_5_N06AX23  \n",
       "2               0              0              0  \n",
       "3               0              0              0  \n",
       "14              0              0              0  \n",
       "15              0              0              0  \n",
       "16              0              0              0  \n",
       "\n",
       "[5 rows x 524 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_use.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The main difference in this experiment from experiment 1 \n",
    "# is that values are imputed so there are no missing values to drop. \n",
    "# This adds a bunch of features\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, GRU, Dense, Dropout, Masking, TimeDistributed\n",
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed\n",
    "from copy import deepcopy\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaler_transform(X_train_use, X_test_use):    \n",
    "    scaler = MinMaxScaler(feature_range=(0, 1)).fit(X_train_use.drop('patient-id', axis=1))\n",
    "    X_train_transformed = pd.DataFrame(scaler.transform(X_train_use.drop('patient-id', axis=1)), \\\n",
    "                                       columns=X_train_use.columns[1:], index=X_train_use.index)                                   \n",
    "    X_train_transformed['patient-id'] = X_train_use['patient-id']\n",
    "    X_test_transformed = pd.DataFrame(scaler.transform(X_test_use.drop('patient-id', axis=1)), \\\n",
    "                                       columns=X_test_use.columns[1:], index=X_test_use.index) \n",
    "    X_test_transformed['patient-id'] = X_test_use['patient-id']\n",
    "    return X_train_transformed, X_test_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_previous_outcome(X, Y):\n",
    "    X = X.copy()\n",
    "    x1, x2 = [], []\n",
    "    pids = X['patient-id'].unique()\n",
    "    for pid in pids:\n",
    "        df = Y[X[X['patient-id']==pid].index]\n",
    "        if(df.shape[0] == 1):\n",
    "            x1.append(pd.Series([0]))\n",
    "            x2.append(pd.Series([0]))\n",
    "        else:\n",
    "            # input 1=(1, 0), 0=(0, 1), NA=(0, 0)\n",
    "            x1.append(pd.Series([0]))\n",
    "            x1.append(df[:-1])\n",
    "            x2.append(pd.Series([0]))\n",
    "            x2.append(df[:-1].map({0: 1, 1: 0}))\n",
    "    X['input_outcome_x'] = pd.Series(pd.concat(x1, ignore_index=True).tolist(), index=X.index)\n",
    "    X['input_outcome_y'] = pd.Series(pd.concat(x2, ignore_index=True).tolist(), index=X.index)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This step converts the outcome to a point in x,y coordinates where fall (1) = (1,0); no fall (0) = (0,1); and NA = (0,0) \n",
    "X_train_use = add_previous_outcome(X_train_use, y_train)\n",
    "X_test_use = add_previous_outcome(X_test_use, y_test)\n",
    "\n",
    "## This step transforms the data to range between 0 and 1\n",
    "X_train_transformed, X_test_transformed = scaler_transform(X_train_use, X_test_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_nested_list(X, Y):\n",
    "    x_list, y_list = [], [] \n",
    "    pids = X['patient-id'].unique()\n",
    "    for pid in pids:\n",
    "        df = X[X['patient-id']==pid]\n",
    "        y_list.append(Y[df.index].values)\n",
    "        x_list.append([record for record in df.drop('patient-id', axis=1).values])\n",
    "    return x_list, y_list\n",
    "\n",
    "def mygenerator(x_list, y_list=None):\n",
    "    if(y_list is not None):\n",
    "        while True:\n",
    "            for x, y in zip(x_list, y_list):\n",
    "                yield np.array(x).reshape((len(x), 1, x[0].shape[0])), y\n",
    "    else:\n",
    "        while True:\n",
    "            for x in x_list:\n",
    "                yield np.array(x).reshape((len(x), 1, x[0].shape[0])) \n",
    "                \n",
    "def fit_model(model, epoch, X_train, y_train, X_valid=None, y_valid=None, verbose=0):\n",
    "    history = model.fit(X_train, y_train, epochs=epoch, verbose=verbose)\n",
    "    if(verbose != 0):\n",
    "        plot_history(history)\n",
    "    return history\n",
    "\n",
    "def plot_roc_curve(fpr, tpr):\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.2f)' % auc(fpr, tpr))\n",
    "    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "def plot_history(history, loss=None, val_loss=None):\n",
    "    if(history is not None):\n",
    "        loss = history.history['loss']\n",
    "    plt.figure()\n",
    "    plt.plot(loss)\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    if('val_loss' in history.history):\n",
    "        val_loss = history.history['val_loss']\n",
    "        plt.plot(val_loss)\n",
    "    plt.legend(['train', 'test'], loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_data(X, maxlen):\n",
    "    return pad_sequences(X, maxlen=maxlen, dtype='float64', padding='post')\n",
    "\n",
    "def pad_all(X_train, y_train, X_test, y_test, maxlen):\n",
    "    return pad_data(X_train, maxlen), pad_data(y_train, maxlen), pad_data(X_test, maxlen), pad_data(y_test, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auroc(y_predict, y_true, plot=False):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_predict, pos_label=1)    \n",
    "    if(plot):\n",
    "        plot_roc_curve(fpr, tpr)\n",
    "    return auc(fpr, tpr)\n",
    "\n",
    "\n",
    "def find_best_f1(y_predict, y_true):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_predict, pos_label=1) \n",
    "    max_f1, th = 0, 0\n",
    "    for threshold in thresholds:\n",
    "        f1 = f1_score(y_true, y_predict > threshold)\n",
    "        if(f1 > max_f1):\n",
    "            max_f1 = f1\n",
    "            th = threshold\n",
    "    return max_f1, th\n",
    "\n",
    "def other_metrics(y_predict, y_true, threshold):\n",
    "    y_threshold = y_predict > threshold\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_threshold).ravel()\n",
    "    return precision_score(y_true, y_threshold), recall_score(y_true, y_threshold),\\\n",
    "            accuracy_score(y_true, y_threshold), float(tn) / (tn + fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "def kfold_validation(unit, ratio, epoch, X, y, groupby, k=5, verbose=0, max_timestamps=20, n_features=101):\n",
    "    auroc_list = []\n",
    "    other_metric_list = []\n",
    "    for train_idx, valid_idx in GroupKFold(n_splits=5).split(X, y, X[groupby]):\n",
    "        X_train, X_valid, y_train, y_valid = X.iloc[train_idx], X.iloc[valid_idx], y.iloc[train_idx], y.iloc[valid_idx]\n",
    "        X_train, y_train = generate_nested_list(X_train, y_train)\n",
    "        X_valid, y_valid = generate_nested_list(X_valid, y_valid)\n",
    "        X_train_pad, y_train_pad, X_valid_pad, y_valid_pad = pad_all(X_train, y_train, X_valid, y_valid, max_timestamps)\n",
    "        y_train_pad = y_train_pad.reshape(y_train_pad.shape[0], y_train_pad.shape[1], 1)\n",
    "        seed(1)\n",
    "        set_random_seed(2)\n",
    "        model = build_model(unit, ratio, max_timestamps, n_features)\n",
    "        fit_model(model, epoch, X_train_pad, y_train_pad, verbose=verbose)\n",
    "        y_valid_len = [len(y) for y in y_valid]\n",
    "        y_predict = model.predict(X_valid_pad)\n",
    "        y_predict = truncate_prediction(y_predict, y_valid_len)\n",
    "        y_true = np.concatenate(y_valid)\n",
    "        auroc_list.append(auroc(y_predict, y_true))\n",
    "        f1, th = find_best_f1(y_predict, y_true)\n",
    "        precision, recall, accuracy, specificity = other_metrics(y_predict, y_true, th)\n",
    "        other_metric_list.append((precision, recall, accuracy, specificity,f1,th))\n",
    "    return (auroc_list, other_metric_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape: (num_of_patients, num_of_records, num_of_features)\n",
    "X_train_list, y_train_list = generate_nested_list(X_train_transformed, y_train)\n",
    "X_test_list, y_test_list = generate_nested_list(X_test_transformed, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## comparing this to the experiment 1 transformed dataset to confirm that this has \n",
    "## diagnoses and ATC codes while the other does not\n",
    "X_train_transformed.to_csv (r'/tmp/exp2_train_transformed_df.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5301, 526)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2283, 526)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "max_timestamps = df.groupby(['patient-id']).size().max()\n",
    "print(max_timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "525\n"
     ]
    }
   ],
   "source": [
    "n_features = X_train_list[0][0].shape[0]\n",
    "print(n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to build an LSTM\n",
    "from keras import regularizers\n",
    "from keras.optimizers import Adagrad, Adadelta\n",
    "def build_model(units, dropout_ratio, n_timesteps, n_dimensions):\n",
    "    model = Sequential()\n",
    "    model.add(Masking(input_shape=(n_timesteps, n_dimensions)))\n",
    "    model.add(LSTM(units, return_sequences=True, recurrent_dropout=dropout_ratio, dropout=0.5))\n",
    "    model.add(TimeDistributed(Dense(1, activation='sigmoid')))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adagrad', metrics=['binary_accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_prediction(y_, y_len):\n",
    "    y_concat = []\n",
    "    for i, y in enumerate(y_):\n",
    "        y_concat.append(np.concatenate(y[:y_len[i], :]))\n",
    "    y_concat = np.concatenate(y_concat)\n",
    "    return y_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "## the data is padded so that the final shape is as follows with the outcome data array having the same\n",
    "## shape but only one value\n",
    "#  array([[patient 1 data record 1],  \n",
    "#         [patient 1 data record 2],\n",
    "#         ...\n",
    "#         [patient 1 data record 19],\n",
    "#        ],\n",
    "#        [[patient 2 data record 1],  \n",
    "#         [patient 2 data record 2],\n",
    "#         ...\n",
    "#         [patient 2 data record 19],\n",
    "#        ],\n",
    "#        ...\n",
    "#       )\n",
    "# \n",
    "X_train_pad, y_train_pad, X_test_pad, y_test_pad = pad_all(X_train_list, y_train_list, X_test_list, y_test_list, max_timestamps)\n",
    "y_train_pad = y_train_pad.reshape((2193, 19, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0423 09:50:02.462745 140353037133632 deprecation_wrapper.py:119] From /usr/local/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0423 09:50:02.465331 140353037133632 deprecation_wrapper.py:119] From /usr/local/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0423 09:50:02.479107 140353037133632 deprecation_wrapper.py:119] From /usr/local/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0423 09:50:02.568729 140353037133632 deprecation_wrapper.py:119] From /usr/local/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0423 09:50:02.578809 140353037133632 deprecation.py:506] From /usr/local/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0423 09:50:03.071312 140353037133632 deprecation.py:323] From /usr/local/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2974: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0423 09:50:03.134570 140353037133632 deprecation_wrapper.py:119] From /usr/local/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0423 09:50:03.152289 140353037133632 deprecation_wrapper.py:119] From /usr/local/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/175\n",
      "2193/2193 [==============================] - 4s 2ms/step - loss: 0.4620 - binary_accuracy: 0.8175\n",
      "Epoch 2/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.4344 - binary_accuracy: 0.8207\n",
      "Epoch 3/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.4194 - binary_accuracy: 0.8257\n",
      "Epoch 4/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.4211 - binary_accuracy: 0.8245\n",
      "Epoch 5/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.4201 - binary_accuracy: 0.8232\n",
      "Epoch 6/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.4166 - binary_accuracy: 0.8230\n",
      "Epoch 7/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.4151 - binary_accuracy: 0.8244\n",
      "Epoch 8/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.4130 - binary_accuracy: 0.8270\n",
      "Epoch 9/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.4061 - binary_accuracy: 0.8267\n",
      "Epoch 10/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.4111 - binary_accuracy: 0.8265\n",
      "Epoch 11/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.4065 - binary_accuracy: 0.8279\n",
      "Epoch 12/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.4068 - binary_accuracy: 0.8300\n",
      "Epoch 13/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.4002 - binary_accuracy: 0.8333\n",
      "Epoch 14/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.4050 - binary_accuracy: 0.8312\n",
      "Epoch 15/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.4028 - binary_accuracy: 0.8294\n",
      "Epoch 16/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3988 - binary_accuracy: 0.8330\n",
      "Epoch 17/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.4018 - binary_accuracy: 0.8316\n",
      "Epoch 18/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.4011 - binary_accuracy: 0.8329\n",
      "Epoch 19/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.4018 - binary_accuracy: 0.8315\n",
      "Epoch 20/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3994 - binary_accuracy: 0.8302\n",
      "Epoch 21/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3989 - binary_accuracy: 0.8330\n",
      "Epoch 22/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.4040 - binary_accuracy: 0.8280\n",
      "Epoch 23/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3957 - binary_accuracy: 0.8338\n",
      "Epoch 24/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.4027 - binary_accuracy: 0.8312\n",
      "Epoch 25/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3964 - binary_accuracy: 0.8333\n",
      "Epoch 26/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3922 - binary_accuracy: 0.8365\n",
      "Epoch 27/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3906 - binary_accuracy: 0.8364\n",
      "Epoch 28/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3972 - binary_accuracy: 0.8321\n",
      "Epoch 29/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3961 - binary_accuracy: 0.8302\n",
      "Epoch 30/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3968 - binary_accuracy: 0.8342\n",
      "Epoch 31/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3879 - binary_accuracy: 0.8377\n",
      "Epoch 32/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3875 - binary_accuracy: 0.8341\n",
      "Epoch 33/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3971 - binary_accuracy: 0.8311\n",
      "Epoch 34/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3946 - binary_accuracy: 0.8334\n",
      "Epoch 35/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3909 - binary_accuracy: 0.8357\n",
      "Epoch 36/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3890 - binary_accuracy: 0.8373\n",
      "Epoch 37/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3865 - binary_accuracy: 0.8362\n",
      "Epoch 38/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3893 - binary_accuracy: 0.8319\n",
      "Epoch 39/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3907 - binary_accuracy: 0.8325\n",
      "Epoch 40/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3910 - binary_accuracy: 0.8373\n",
      "Epoch 41/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3906 - binary_accuracy: 0.8359\n",
      "Epoch 42/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3884 - binary_accuracy: 0.8380\n",
      "Epoch 43/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3904 - binary_accuracy: 0.8344\n",
      "Epoch 44/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3836 - binary_accuracy: 0.8374\n",
      "Epoch 45/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3874 - binary_accuracy: 0.8348\n",
      "Epoch 46/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3900 - binary_accuracy: 0.8278\n",
      "Epoch 47/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3855 - binary_accuracy: 0.8397\n",
      "Epoch 48/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3831 - binary_accuracy: 0.8417\n",
      "Epoch 49/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3824 - binary_accuracy: 0.8386\n",
      "Epoch 50/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3889 - binary_accuracy: 0.8338\n",
      "Epoch 51/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3845 - binary_accuracy: 0.8409\n",
      "Epoch 52/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3901 - binary_accuracy: 0.8336\n",
      "Epoch 53/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3831 - binary_accuracy: 0.8407\n",
      "Epoch 54/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3883 - binary_accuracy: 0.8323\n",
      "Epoch 55/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3909 - binary_accuracy: 0.8323\n",
      "Epoch 56/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3885 - binary_accuracy: 0.8327\n",
      "Epoch 57/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3829 - binary_accuracy: 0.8373\n",
      "Epoch 58/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3903 - binary_accuracy: 0.8340\n",
      "Epoch 59/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3853 - binary_accuracy: 0.8348\n",
      "Epoch 60/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3859 - binary_accuracy: 0.8403\n",
      "Epoch 61/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3855 - binary_accuracy: 0.8375\n",
      "Epoch 62/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3811 - binary_accuracy: 0.8396\n",
      "Epoch 63/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3824 - binary_accuracy: 0.8355\n",
      "Epoch 64/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3796 - binary_accuracy: 0.8379\n",
      "Epoch 65/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3780 - binary_accuracy: 0.8374\n",
      "Epoch 66/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3831 - binary_accuracy: 0.8361\n",
      "Epoch 67/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3840 - binary_accuracy: 0.8390\n",
      "Epoch 68/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3841 - binary_accuracy: 0.8347\n",
      "Epoch 69/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3775 - binary_accuracy: 0.8408\n",
      "Epoch 70/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3780 - binary_accuracy: 0.8376\n",
      "Epoch 71/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3785 - binary_accuracy: 0.8394\n",
      "Epoch 72/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3813 - binary_accuracy: 0.8361\n",
      "Epoch 73/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3819 - binary_accuracy: 0.8417\n",
      "Epoch 74/175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3748 - binary_accuracy: 0.8442\n",
      "Epoch 75/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3757 - binary_accuracy: 0.8444\n",
      "Epoch 76/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3812 - binary_accuracy: 0.8373\n",
      "Epoch 77/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3782 - binary_accuracy: 0.8399\n",
      "Epoch 78/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3728 - binary_accuracy: 0.8413\n",
      "Epoch 79/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3775 - binary_accuracy: 0.8381\n",
      "Epoch 80/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3760 - binary_accuracy: 0.8400\n",
      "Epoch 81/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3776 - binary_accuracy: 0.8388\n",
      "Epoch 82/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3766 - binary_accuracy: 0.8399\n",
      "Epoch 83/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3791 - binary_accuracy: 0.8362\n",
      "Epoch 84/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3735 - binary_accuracy: 0.8400\n",
      "Epoch 85/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3760 - binary_accuracy: 0.8381\n",
      "Epoch 86/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3778 - binary_accuracy: 0.8402\n",
      "Epoch 87/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3745 - binary_accuracy: 0.8427\n",
      "Epoch 88/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3725 - binary_accuracy: 0.8432\n",
      "Epoch 89/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3761 - binary_accuracy: 0.8393\n",
      "Epoch 90/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3749 - binary_accuracy: 0.8396\n",
      "Epoch 91/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3746 - binary_accuracy: 0.8443\n",
      "Epoch 92/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3780 - binary_accuracy: 0.8386\n",
      "Epoch 93/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3696 - binary_accuracy: 0.8457\n",
      "Epoch 94/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3758 - binary_accuracy: 0.8413\n",
      "Epoch 95/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3777 - binary_accuracy: 0.8390\n",
      "Epoch 96/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3756 - binary_accuracy: 0.8360\n",
      "Epoch 97/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3701 - binary_accuracy: 0.8419\n",
      "Epoch 98/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3747 - binary_accuracy: 0.8419\n",
      "Epoch 99/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3731 - binary_accuracy: 0.8424\n",
      "Epoch 100/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3680 - binary_accuracy: 0.8434\n",
      "Epoch 101/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3673 - binary_accuracy: 0.8452\n",
      "Epoch 102/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3707 - binary_accuracy: 0.8425\n",
      "Epoch 103/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3652 - binary_accuracy: 0.8445\n",
      "Epoch 104/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3706 - binary_accuracy: 0.8443\n",
      "Epoch 105/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3671 - binary_accuracy: 0.8409\n",
      "Epoch 106/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3740 - binary_accuracy: 0.8435\n",
      "Epoch 107/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3751 - binary_accuracy: 0.8382\n",
      "Epoch 108/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3704 - binary_accuracy: 0.8437\n",
      "Epoch 109/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3742 - binary_accuracy: 0.8442\n",
      "Epoch 110/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3690 - binary_accuracy: 0.8418\n",
      "Epoch 111/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3688 - binary_accuracy: 0.8443\n",
      "Epoch 112/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3723 - binary_accuracy: 0.8411\n",
      "Epoch 113/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3651 - binary_accuracy: 0.8439\n",
      "Epoch 114/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3761 - binary_accuracy: 0.8377\n",
      "Epoch 115/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3726 - binary_accuracy: 0.8415\n",
      "Epoch 116/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3621 - binary_accuracy: 0.8458\n",
      "Epoch 117/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3654 - binary_accuracy: 0.8487\n",
      "Epoch 118/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3646 - binary_accuracy: 0.8444\n",
      "Epoch 119/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3702 - binary_accuracy: 0.8413\n",
      "Epoch 120/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3651 - binary_accuracy: 0.8449\n",
      "Epoch 121/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3609 - binary_accuracy: 0.8471\n",
      "Epoch 122/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3685 - binary_accuracy: 0.8405\n",
      "Epoch 123/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3696 - binary_accuracy: 0.8355\n",
      "Epoch 124/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3659 - binary_accuracy: 0.8422\n",
      "Epoch 125/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3666 - binary_accuracy: 0.8428\n",
      "Epoch 126/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3682 - binary_accuracy: 0.8468\n",
      "Epoch 127/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3617 - binary_accuracy: 0.8471\n",
      "Epoch 128/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3648 - binary_accuracy: 0.8438\n",
      "Epoch 129/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3664 - binary_accuracy: 0.8433\n",
      "Epoch 130/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3647 - binary_accuracy: 0.8471\n",
      "Epoch 131/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3618 - binary_accuracy: 0.8480\n",
      "Epoch 132/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3558 - binary_accuracy: 0.8462\n",
      "Epoch 133/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3614 - binary_accuracy: 0.8468\n",
      "Epoch 134/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3579 - binary_accuracy: 0.8472\n",
      "Epoch 135/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3589 - binary_accuracy: 0.8444\n",
      "Epoch 136/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3632 - binary_accuracy: 0.8470\n",
      "Epoch 137/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3639 - binary_accuracy: 0.8447\n",
      "Epoch 138/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3640 - binary_accuracy: 0.8448\n",
      "Epoch 139/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3652 - binary_accuracy: 0.8464\n",
      "Epoch 140/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3599 - binary_accuracy: 0.8484\n",
      "Epoch 141/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3633 - binary_accuracy: 0.8434\n",
      "Epoch 142/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3633 - binary_accuracy: 0.8463\n",
      "Epoch 143/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3600 - binary_accuracy: 0.8416\n",
      "Epoch 144/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3647 - binary_accuracy: 0.8443\n",
      "Epoch 145/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3631 - binary_accuracy: 0.8486\n",
      "Epoch 146/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3575 - binary_accuracy: 0.8492\n",
      "Epoch 147/175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3659 - binary_accuracy: 0.8462\n",
      "Epoch 148/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3611 - binary_accuracy: 0.8475\n",
      "Epoch 149/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3569 - binary_accuracy: 0.8467\n",
      "Epoch 150/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3585 - binary_accuracy: 0.8495\n",
      "Epoch 151/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3611 - binary_accuracy: 0.8462\n",
      "Epoch 152/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3555 - binary_accuracy: 0.8508\n",
      "Epoch 153/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3618 - binary_accuracy: 0.8443\n",
      "Epoch 154/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3607 - binary_accuracy: 0.8448\n",
      "Epoch 155/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3589 - binary_accuracy: 0.8485\n",
      "Epoch 156/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3595 - binary_accuracy: 0.8478\n",
      "Epoch 157/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3549 - binary_accuracy: 0.8513\n",
      "Epoch 158/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3599 - binary_accuracy: 0.8420\n",
      "Epoch 159/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3597 - binary_accuracy: 0.8475\n",
      "Epoch 160/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3553 - binary_accuracy: 0.8462\n",
      "Epoch 161/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3568 - binary_accuracy: 0.8502\n",
      "Epoch 162/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3634 - binary_accuracy: 0.8402\n",
      "Epoch 163/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3572 - binary_accuracy: 0.8466\n",
      "Epoch 164/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3554 - binary_accuracy: 0.8514\n",
      "Epoch 165/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3597 - binary_accuracy: 0.8417\n",
      "Epoch 166/175\n",
      "2193/2193 [==============================] - 3s 1ms/step - loss: 0.3598 - binary_accuracy: 0.8468\n",
      "Epoch 167/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3560 - binary_accuracy: 0.8501\n",
      "Epoch 168/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3567 - binary_accuracy: 0.8494\n",
      "Epoch 169/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3579 - binary_accuracy: 0.8475\n",
      "Epoch 170/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3616 - binary_accuracy: 0.8468\n",
      "Epoch 171/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3573 - binary_accuracy: 0.8444\n",
      "Epoch 172/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3511 - binary_accuracy: 0.8520\n",
      "Epoch 173/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3576 - binary_accuracy: 0.8498\n",
      "Epoch 174/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3539 - binary_accuracy: 0.8518\n",
      "Epoch 175/175\n",
      "2193/2193 [==============================] - 2s 1ms/step - loss: 0.3528 - binary_accuracy: 0.8495\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auroc:  0.7031970538667999\n",
      "f1:  0.4170073589533933\n",
      "threshold:  0.15926597\n",
      "precision:  0.3227848101265823\n",
      "recall:  0.5889145496535797\n",
      "accuracy:  0.6876916338151555\n",
      "specificity:  0.7108108108108108\n",
      "CPU times: user 28min 28s, sys: 5min 23s, total: 33min 51s\n",
      "Wall time: 7min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### A single run w/out cross-validation\n",
    "# with previous outcome added to the features\n",
    "# outcome is added before scaling\n",
    "seed(1)\n",
    "set_random_seed(2)\n",
    "model = build_model(32, 0.5, max_timestamps, n_features)\n",
    "fit_model(model, 175, X_train_pad, y_train_pad, verbose=1)\n",
    "y_predict = model.predict(X_test_pad)\n",
    "y_test_len = [len(y) for y in y_test_list]\n",
    "y_predict = truncate_prediction(y_predict, y_test_len)\n",
    "y_true = np.concatenate(y_test_list)\n",
    "print('auroc: ', auroc(y_predict, y_true))\n",
    "f1, th = find_best_f1(y_predict, y_true)\n",
    "print('f1: ', f1);\n",
    "print('threshold: ', th)\n",
    "precision, recall, accuracy, specificity = other_metrics(y_predict, y_true, th)\n",
    "print('precision: ', precision)\n",
    "print('recall: ', recall)\n",
    "print('accuracy: ', accuracy)\n",
    "print('specificity: ', specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run 5-fold cross-validation to get average performance characteristics\n",
    "unit = 32\n",
    "ratio = 0.5\n",
    "epoch = 225\n",
    "(auroc_list, other_metric_list) = kfold_validation(unit, ratio, epoch, X_train_transformed, y_train, 'patient-id', verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
